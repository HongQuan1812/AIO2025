{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12003571,"sourceType":"datasetVersion","datasetId":7551087}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score, f1_score\n\n\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:11:11.288290Z","iopub.execute_input":"2025-05-30T07:11:11.288825Z","iopub.status.idle":"2025-05-30T07:11:39.669004Z","shell.execute_reply.started":"2025-05-30T07:11:11.288799Z","shell.execute_reply":"2025-05-30T07:11:39.668288Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if GPU is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:11:39.670165Z","iopub.execute_input":"2025-05-30T07:11:39.670471Z","iopub.status.idle":"2025-05-30T07:11:39.752991Z","shell.execute_reply.started":"2025-05-30T07:11:39.670453Z","shell.execute_reply":"2025-05-30T07:11:39.752378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:11:39.753786Z","iopub.execute_input":"2025-05-30T07:11:39.754089Z","iopub.status.idle":"2025-05-30T07:11:39.770317Z","shell.execute_reply.started":"2025-05-30T07:11:39.754061Z","shell.execute_reply":"2025-05-30T07:11:39.769736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_paths = {\n    'train': '/kaggle/input/aiomodule6cassavaleaf/cassavaleafdata/train',\n    'valid': '/kaggle/input/aiomodule6cassavaleaf/cassavaleafdata/validation',\n    'test' : '/kaggle/input/aiomodule6cassavaleaf/cassavaleafdata/test'\n}\n\n# load image from path\ndef loader(path):\n    return Image.open(path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:11:39.770989Z","iopub.execute_input":"2025-05-30T07:11:39.771217Z","iopub.status.idle":"2025-05-30T07:11:39.787107Z","shell.execute_reply.started":"2025-05-30T07:11:39.771190Z","shell.execute_reply":"2025-05-30T07:11:39.786460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_size = 150\ntrain_transforms = transforms.Compose([\n    transforms.Resize ((150, 150)), # Resize image\n    transforms.ToTensor(), # convert to Tensor and normalise to range [0, 1] \n])\n\ntrain_data = datasets.ImageFolder(\n    root = data_paths['train'],\n    loader = loader,\n    transform = train_transforms\n)\n\nvalid_data = datasets.ImageFolder(\n    root = data_paths['valid'],\n    transform = train_transforms\n)\n\ntest_data = datasets.ImageFolder(\n    root = data_paths['test'],\n    transform = train_transforms\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:11:39.788943Z","iopub.execute_input":"2025-05-30T07:11:39.789170Z","iopub.status.idle":"2025-05-30T07:11:48.120906Z","shell.execute_reply.started":"2025-05-30T07:11:39.789156Z","shell.execute_reply":"2025-05-30T07:11:48.120091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = []\ny_train = []\n\nX_val = []\ny_val = []\n\nX_test = []\ny_test = []\n\n# Loop over the dataset to extract all images and labels\nfor img, label in train_data:\n    X_train.append(img)        # img is already transformed (e.g., tensor)\n    y_train.append(label)      # label is an int\n\n# Stack into tensors\nX_train = torch.stack(X_train)           # shape: [N, C, H, W]\ny_train = torch.tensor(y_train)          # shape: [N]\n\nfor img, label in test_data:\n    X_test.append(img)\n    y_test.append(label)\n\nX_test = torch.stack(X_test)\ny_test = torch.tensor(y_test)\n\nfor img, label in valid_data:\n    X_val.append(img)\n    y_val.append(label)\n\nX_val = torch.stack(X_val)\ny_val = torch.tensor(y_val)\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"y_test shape:\", y_test.shape)\nprint(\"X_val shape:\", X_val.shape)\nprint(\"y_val shape:\", y_val.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:11:48.121768Z","iopub.execute_input":"2025-05-30T07:11:48.122172Z","iopub.status.idle":"2025-05-30T07:13:42.958757Z","shell.execute_reply.started":"2025-05-30T07:11:48.122141Z","shell.execute_reply":"2025-05-30T07:13:42.957878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"channel_means = X_train.float().mean(dim = (0, 2, 3))\nchannel_stds = X_train.float().std(dim = (0, 2, 3))\nchannel_means.shape, channel_stds.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:13:42.959600Z","iopub.execute_input":"2025-05-30T07:13:42.959891Z","iopub.status.idle":"2025-05-30T07:13:44.971104Z","shell.execute_reply.started":"2025-05-30T07:13:42.959872Z","shell.execute_reply":"2025-05-30T07:13:44.970438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomDataset(data.Dataset):\n    def __init__(self, X, y):\n        super().__init__()\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, index):\n        return self.X[index], self.y[index]\n\n    def transforms(self, transforms):\n        self.X = transforms(self.X)\n        \n        \ntrain_data = CustomDataset(X_train, y_train)\ntest_data = CustomDataset(X_test, y_test)\nval_data = CustomDataset(X_val, y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:13:44.971944Z","iopub.execute_input":"2025-05-30T07:13:44.972171Z","iopub.status.idle":"2025-05-30T07:13:44.977912Z","shell.execute_reply.started":"2025-05-30T07:13:44.972153Z","shell.execute_reply":"2025-05-30T07:13:44.977309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.RandomCrop(150, padding = 2),\n    transforms.RandomErasing(\n        p = 0.75,\n        scale = (0.01, 0.3),\n        ratio = (1.0, 1.0),\n        value = 0,\n        inplace = True\n    ),\n    transforms.RandomHorizontalFlip(p = 0.5),\n    transforms.Normalize(mean = channel_means.tolist(), std = channel_stds.tolist())\n])\n\nval_transform = transforms.Compose([\n    transforms.Normalize(mean = channel_means.tolist(), std = channel_stds.tolist())\n])\n\ntrain_data.transforms(train_transform)\ntest_data.transforms(val_transform)\nval_data.transforms(val_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:13:44.979023Z","iopub.execute_input":"2025-05-30T07:13:44.979225Z","iopub.status.idle":"2025-05-30T07:13:47.981583Z","shell.execute_reply.started":"2025-05-30T07:13:44.979208Z","shell.execute_reply":"2025-05-30T07:13:47.980801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_data), train_data[0][0].shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:13:47.982437Z","iopub.execute_input":"2025-05-30T07:13:47.982648Z","iopub.status.idle":"2025-05-30T07:13:47.987285Z","shell.execute_reply.started":"2025-05-30T07:13:47.982632Z","shell.execute_reply":"2025-05-30T07:13:47.986587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch = 32\n\ntrain_loader = data.DataLoader(\n    dataset = train_data,\n    batch_size = batch,\n    shuffle = True\n)\n\ntest_loader = data.DataLoader(\n    dataset = test_data,\n    batch_size = batch,\n    shuffle = False\n)\n\nval_loader = data.DataLoader(\n    dataset = val_data,\n    batch_size = batch,\n    shuffle = False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:13:47.987991Z","iopub.execute_input":"2025-05-30T07:13:47.988232Z","iopub.status.idle":"2025-05-30T07:13:48.007399Z","shell.execute_reply.started":"2025-05-30T07:13:47.988207Z","shell.execute_reply":"2025-05-30T07:13:48.006835Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"next(iter(train_loader))[0].shape\n# batch: 256\n# channels: 3 (RGB)\n# w x h : 150 x 150","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:13:48.008034Z","iopub.execute_input":"2025-05-30T07:13:48.008241Z","iopub.status.idle":"2025-05-30T07:13:48.042049Z","shell.execute_reply.started":"2025-05-30T07:13:48.008225Z","shell.execute_reply":"2025-05-30T07:13:48.041279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(next(iter(train_loader))[1].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:13:48.042793Z","iopub.execute_input":"2025-05-30T07:13:48.043046Z","iopub.status.idle":"2025-05-30T07:13:48.093281Z","shell.execute_reply.started":"2025-05-30T07:13:48.043029Z","shell.execute_reply":"2025-05-30T07:13:48.092674Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass SkipConnection(nn.Module):\n    def __init__(self, in_ch):\n        super().__init__()\n\n        self.normal_path = nn.Sequential(\n            nn.Conv2d(in_ch, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.1),\n\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.1),\n\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n        )\n\n        if in_ch != 64:\n            self.projection_path = nn.Sequential(\n                nn.Conv2d(in_ch, 64, kernel_size=3, stride=1, padding=1),\n                nn.BatchNorm2d(64),\n            )\n        else:\n            self.projection_path = nn.Sequential()\n\n        self.leakyrelu = nn.LeakyReLU(0.1)\n        \n\n    def forward(self, x):\n        x_project = self.projection_path(x)\n        x_normal = self.normal_path(x)\n        x = x_project + x_normal\n        x = self.leakyrelu(x)\n        return x\n    \n\nclass CNN(nn.Module):\n    def __init__(self, num_classes, num_blocks):\n        super().__init__()\n\n        blocks = [\n            SkipConnection(3),\n            nn.MaxPool2d(2, 2),\n            nn.Dropout(0.2),\n        ]\n        \n        for _ in range(1, num_blocks):\n            block = [\n                SkipConnection(64),\n                nn.MaxPool2d(2, 2),\n                nn.Dropout(0.2),\n            ]\n            blocks.extend(block)\n        \n        self.feature_extractor = nn.Sequential(*blocks)\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64*4*4, 128),\n            nn.BatchNorm1d(128),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.2),\n\n            nn.Linear(128, 128),\n            nn.BatchNorm1d(128),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.2),\n\n            nn.Linear(128, num_classes)\n        )\n\n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        generator = torch.Generator().manual_seed(42)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_uniform_(m.weight, a=0.1, mode='fan_in', nonlinearity='leaky_relu', generator=generator)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.kaiming_uniform_(m.weight, a=0, mode='fan_in', nonlinearity='leaky_relu', generator=generator)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.feature_extractor(x)\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T08:56:44.481083Z","iopub.execute_input":"2025-05-30T08:56:44.481714Z","iopub.status.idle":"2025-05-30T08:56:44.493509Z","shell.execute_reply.started":"2025-05-30T08:56:44.481666Z","shell.execute_reply":"2025-05-30T08:56:44.492813Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = len(next(iter(train_loader))[1].unique())\nmodel = CNN(num_classes = num_classes, num_blocks = 5)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T08:56:44.914332Z","iopub.execute_input":"2025-05-30T08:56:44.914533Z","iopub.status.idle":"2025-05-30T08:56:44.938627Z","shell.execute_reply.started":"2025-05-30T08:56:44.914517Z","shell.execute_reply":"2025-05-30T08:56:44.938117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torchsummary import summary\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nsummary(model, (3, 150, 150))  # Input shape does NOT include batch size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T08:56:47.491226Z","iopub.execute_input":"2025-05-30T08:56:47.491496Z","iopub.status.idle":"2025-05-30T08:56:47.516287Z","shell.execute_reply.started":"2025-05-30T08:56:47.491474Z","shell.execute_reply":"2025-05-30T08:56:47.515562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Set up Training Session","metadata":{}},{"cell_type":"code","source":"from typing import Literal, Optional\nclass training_model:\n    def __init__(self, model, train_loader, val_loader, test_loader, optimizer, criterion, scheduler: callable = None, metrics: dict[str, callable] = {\"Accuracy\": (accuracy_score, {})}, refit: str = \"Accuracy\"):\n        self.model = model\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.test_loader = test_loader\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.metrics = metrics\n        self.refit = refit\n        self.best_model_state = None\n        self.scheduler = scheduler\n\n    # Define train function\n    def train_session(self):\n        train_loss = 0\n        total_samples = 0\n        \n        y_train_label_pred = []\n        y_train_label_true = []\n\n        metric_dict_train = {}\n\n        # training session\n        self.model.train()\n        for X_train, y_train in self.train_loader:\n            # X_train: (batch_size, in_channels, height, width)\n            # y_train: (batch_size)\n\n            y_train = y_train.to(device)\n            X_train = X_train.to(device)\n            \n            self.optimizer.zero_grad() # reset optimizer gradients\n\n            # forward pass\n            output = self.model(X_train) # output: (batch_size, num_classes)\n\n            # calculate loss\n            loss = self.criterion(output, y_train)\n            train_loss += loss.item() * len(y_train)\n            total_samples += len(y_train)\n\n            # Predictions\n            y_train_label_true.extend(y_train.tolist())\n            y_train_label_pred.extend(torch.argmax(output, dim=1).tolist())\n\n            # calculate gradients\n            loss.backward()\n\n            # update weights\n            self.optimizer.step()\n        \n        train_loss /= total_samples\n\n        for metric_name, (metric_func, kwargs) in self.metrics.items():\n            metric = metric_func(y_train_label_true, y_train_label_pred, **kwargs)\n            metric_dict_train[metric_name] = metric\n\n        return train_loss, metric_dict_train\n    \n    # Define validation (testing) function\n    def eval_session(self, mode: Literal['Eval', 'Test'] = 'Eval'):\n        # validation session\n        self.model.eval()\n        with torch.no_grad():\n            if mode == \"Eval\":\n                val_loss = 0\n                total_samples = 0\n\n                y_val_label_pred = []\n                y_val_label_true = []\n\n                metric_dict_val = {}\n                for X_val, y_val in self.val_loader:\n                    # X_val: (batch_size, in_channels, height, width)\n                    # y_val: (batch_size)\n    \n                    y_val = y_val.to(device)\n                    X_val = X_val.to(device)\n                    \n                    # forward pass\n                    output = self.model(X_val) # output: (batch_size, num_classes)\n    \n                    # calculate loss\n                    loss = self.criterion(output, y_val)\n                    val_loss += loss.item() * len(y_val)\n                    total_samples += len(y_val)\n    \n                    # Predictions\n                    y_val_label_true.extend(y_val.tolist())\n                    y_val_label_pred.extend(torch.argmax(output, dim=1).tolist())\n            \n                val_loss /= total_samples\n        \n                for metric_name, (metric_func, kwargs) in self.metrics.items():\n                    metric = metric_func(y_val_label_true, y_val_label_pred, **kwargs)\n                    metric_dict_val[metric_name] = metric\n        \n                return val_loss, metric_dict_val\n            elif mode == \"Test\":\n                test_loss = 0\n                total_samples = 0\n\n                y_test_label_pred = []\n                y_test_label_true = []\n\n                metric_dict_test = {}\n                for X_test, y_test in self.test_loader:\n                    # X_test: (batch_size, in_channels, height, width)\n                    # y_test: (batch_size)\n    \n                    y_test = y_test.to(device)\n                    X_test = X_test.to(device)\n                    \n                    # forward pass\n                    output = self.model(X_test) # output: (batch_size, num_classes)\n    \n                    # calculate loss\n                    loss = self.criterion(output, y_test)\n                    test_loss += loss.item() * len(y_test)\n                    total_samples += len(y_test)\n    \n                    # Predictions\n                    y_test_label_true.extend(y_test.tolist())\n                    y_test_label_pred.extend(torch.argmax(output, dim=1).tolist())\n            \n                test_loss /= total_samples\n        \n                for metric_name, (metric_func, kwargs) in self.metrics.items():\n                    metric = metric_func(y_test_label_true, y_test_label_pred, **kwargs)\n                    metric_dict_test[metric_name] = metric\n        \n                return test_loss, metric_dict_test\n                \n\n    def train(self, epochs):\n        train_lossess = []\n        val_lossess = []\n\n        metric_dict_train_collect = {}\n        metric_dict_val_collect = {}\n\n        best_score = 0.0\n\n        for epoch in range(epochs):\n            score_collect_val = ''\n            score_collect_train = ''\n            \n            train_loss, metric_dict_train = self.train_session()\n            val_loss, metric_dict_val = self.eval_session()\n\n            # save loss and accuracy\n            train_lossess.append(train_loss)\n            val_lossess.append(val_loss)\n\n            for metric_name, metric_value in metric_dict_train.items():\n                if metric_name not in metric_dict_train_collect:\n                    metric_dict_train_collect[metric_name] = []\n                metric_dict_train_collect[metric_name].append(metric_value)\n\n                score_collect_train += f'- {metric_name}: {metric_value}'\n\n            for metric_name, metric_value in metric_dict_val.items():\n                if metric_name not in metric_dict_val_collect:\n                    metric_dict_val_collect[metric_name] = []\n                metric_dict_val_collect[metric_name].append(metric_value)\n\n                score_collect_val += f'- {metric_name}: {metric_value}'\n\n                if metric_name == self.refit:\n                    # Save best model based on validation F1 score\n                    if metric_value > best_score:\n                        best_score = metric_value\n                        self.best_model_state = self.model.state_dict()\n                        print(\"=====================\")\n                        print(f\"Epoch {epoch+1}: New best {metric_name} on val = {best_score}, saving model...\") \n                        print(\"=====================\")\n\n            print(f'Epoch {epoch + 1} completed - Val Loss: {val_loss} ' + score_collect_val + f' - Train Loss: {train_loss} ' + score_collect_train) \n            \n            if self.scheduler is not None:\n                self.scheduler.step()\n        return train_lossess, val_lossess, metric_dict_train_collect, metric_dict_val_collect, self.best_model_state\n\n    def test(self):\n        best_model_state = self.best_model_state\n        self.model.load_state_dict(best_model_state)\n\n        score_collect = ''\n        test_loss, metric_dict_test = self.eval_session(mode = \"Test\")\n        \n        for metric_name, metric_value in metric_dict_test.items():\n            score_collect += f'- {metric_name}: {metric_value}'\n\n        print(f'Test session - Test Loss: {test_loss} ' + score_collect)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T08:57:00.022120Z","iopub.execute_input":"2025-05-30T08:57:00.022408Z","iopub.status.idle":"2025-05-30T08:57:00.042592Z","shell.execute_reply.started":"2025-05-30T08:57:00.022386Z","shell.execute_reply":"2025-05-30T08:57:00.041732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR, ExponentialLR\nepochs = 100\nin_channels = next(iter(train_loader))[0].shape[1]\nnum_classes = len(next(iter(train_loader))[1].unique())\nmodel = CNN(num_classes = num_classes, num_blocks = 5)\n\nmodel = model.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.01)\n# Decay LR by gamma every step_size epochs\n#scheduler = ExponentialLR(optimizer, gamma=0.9888)\nscheduler = StepLR(optimizer, step_size=10, gamma=0.9)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T08:57:00.044085Z","iopub.execute_input":"2025-05-30T08:57:00.044279Z","iopub.status.idle":"2025-05-30T08:57:00.088299Z","shell.execute_reply.started":"2025-05-30T08:57:00.044263Z","shell.execute_reply":"2025-05-30T08:57:00.087632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training = training_model(\n    model = model,\n    train_loader = train_loader,\n    val_loader = val_loader,\n    test_loader = test_loader,\n    optimizer = optimizer,\n    criterion = criterion,\n    scheduler = scheduler,\n    metrics = {\"F1 Score\": (f1_score, {\"average\" : \"macro\"})},\n    refit = \"F1 Score\"\n)\ntrain_lossess, val_lossess, metric_dict_train_collect, metric_dict_val_collect, best_model_state = training.train(epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T08:57:00.088972Z","iopub.execute_input":"2025-05-30T08:57:00.089191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(15, 10))\nax[0].plot(train_lossess, color='green', label = 'Train Loss')\nax[0].plot(val_lossess, color='orange', label = 'Val Loss')\nax[0].set(xlabel='Epoch', ylabel='Loss')\nax[0].set_title('Loss for Train & Val')\nax[0].legend()\n\nax[1].plot(metric_dict_train_collect['F1 Score'], color='green', label = 'F1 Train')\nax[1].plot(metric_dict_val_collect['F1 Score'], color='orange', label = 'F1 Val')\nax[1].set(xlabel='Epoch', ylabel='F1 Score')\nax[1].set_title('F1 for Train & Val')\nax[1].legend()\n\nplt.tight_layout()\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training.test()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}